{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Objective\n","metadata":{}},{"cell_type":"markdown","source":"## Demonstate via code how Docker and AWS ECR interacts to:\n* Pushing Images\n* Pulling Images\n* Logging In\n* Listing Repositories\n* Deleting Images\n* Managing Lifecycle Policies\n* Integrating with CI/CD\n* Scanning Images\n* Copying Images\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Push image\nTo push a Docker image to an AWS Elastic Container Registry (ECR) using Python, you can use the AWS SDK for Python, commonly known as Boto3. Before running the code, make sure you have the AWS CLI installed and configured with your AWS credentials.\n\nBelow is the Python script to push a Docker image to an AWS ECR repository:","metadata":{}},{"cell_type":"code","source":"import boto3\nimport subprocess\n\n# Set your AWS region and ECR repository name\naws_region = 'your-aws-region'\necr_repository_name = 'your-ecr-repo-name'\n\n# Create a Boto3 ECR client\necr_client = boto3.client('ecr', region_name=aws_region)\n\n# Get the ECR login token to authenticate Docker to your registry\necr_login = ecr_client.get_authorization_token()\nregistry = ecr_login['authorizationData'][0]['proxyEndpoint']\nusername = 'AWS'\npassword = ecr_login['authorizationData'][0]['authorizationToken']\ndocker_login_command = f'docker login -u {username} -p {password} {registry}'\n\n# Log in to the ECR registry\nsubprocess.call(docker_login_command, shell=True)\n\n# Build your Docker image (replace 'path_to_Dockerfile' and 'tag' with your values)\ndocker_build_command = f'docker build -t {ecr_repository_name} -f path_to_Dockerfile .'\nsubprocess.call(docker_build_command, shell=True)\n\n# Tag the Docker image for the ECR repository\ndocker_tag_command = f'docker tag {ecr_repository_name}:latest {registry}/{ecr_repository_name}:latest'\nsubprocess.call(docker_tag_command, shell=True)\n\n# Push the Docker image to ECR\ndocker_push_command = f'docker push {registry}/{ecr_repository_name}:latest'\nsubprocess.call(docker_push_command, shell=True)\n\nprint(f'Docker image {ecr_repository_name} pushed to ECR repository {ecr_repository_name}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Customize for your use case\nReplace the following placeholders with your specific values:\n\n* 'your-aws-region': Replace with your AWS region (e.g., 'us-east-1').\n* 'your-ecr-repo-name': Replace with the name of your ECR repository.\n* 'path_to_Dockerfile': Replace with the path to your Dockerfile.\n* 'tag': Replace with the desired tag for your Docker image.","metadata":{}},{"cell_type":"markdown","source":"# Prupose of this script does the following:\n\n1. Initializes a Boto3 ECR client.\n2. Retrieves an authentication token for Docker to log in to your ECR registry.\n3. Logs in to the ECR registry using Docker.\n4. Builds your Docker image.\n5. Tags the Docker image with the ECR repository URI.\n6. Pushes the Docker image to the specified ECR repository.\n\n\n# Note:\nMake sure you have the necessary AWS IAM permissions to perform these operations on your ECR repository.","metadata":{}},{"cell_type":"markdown","source":"## 2. Pulling Images:\n\nUse the docker-py library to pull Docker images from an ECR repository in Python:","metadata":{}},{"cell_type":"code","source":"import docker\n\n# Initialize the Docker client\nclient = docker.from_env()\n\n# Replace with your ECR image URL and credentials\nimage_url = 'your-account-id.dkr.ecr.your-region.amazonaws.com/your-repo:your-tag'\nusername = 'AWS'\npassword = '<your-ecr-password>'\n\n# Log in to ECR\nclient.login(username=username, password=password, registry=image_url)\n\n# Pull the image\nclient.images.pull(image_url)\n\nprint(f'Pulled image: {image_url}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Logging In:\n\nLogging in to ECR using Python and the AWS SDK (Boto3) is similar to the command-line example mentioned earlier:","metadata":{}},{"cell_type":"code","source":"import boto3\nimport docker\n\n# Initialize AWS and ECR clients\necr_client = boto3.client('ecr', region_name='your-region')\ndocker_client = docker.from_env()\n\n# Get the ECR login token\nresponse = ecr_client.get_authorization_token()\ntoken = response['authorizationData'][0]['authorizationToken']\nusername, password = base64.b64decode(token).decode().split(':')\n\n# Log in to ECR\ndocker_client.login(username, password, registry='your-account-id.dkr.ecr.your-region.amazonaws.com')\n\nprint('Logged in to ECR')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Listing Repositories:\n\nList ECR repositories using the AWS SDK (Boto3) in Python:","metadata":{}},{"cell_type":"code","source":"import boto3\n\n# Initialize the ECR client\necr_client = boto3.client('ecr', region_name='your-region')\n\n# List ECR repositories\nresponse = ecr_client.describe_repositories()\nrepositories = response['repositories']\n\nfor repo in repositories:\n    print(f\"Repository Name: {repo['repositoryName']}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Scanning Images:\n\nInitiate image scans using the AWS SDK (Boto3) in Python:","metadata":{}},{"cell_type":"code","source":"import boto3\n\n# Initialize the ECR client\necr_client = boto3.client('ecr', region_name='your-region')\n\n# Specify the repository and image tag\nrepository_name = 'your-repo'\nimage_tag = 'your-tag'\n\n# Start an image scan\nresponse = ecr_client.start_image_scan(\n    repositoryName=repository_name,\n    imageId={'imageTag': image_tag}\n)\n\nprint(f\"Scan status: {response['imageScanStatus']['status']}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Deleting Images:\n**2 methods**\n1. Directly via AWS CLI\n2. Python scipt that automates the process","metadata":{}},{"cell_type":"markdown","source":"### 1. Directly via AWS CLI","metadata":{}},{"cell_type":"markdown","source":"**Step 1: List Images in the Repository**\n\nBefore deleting images, you need to list the images in the repository to identify the image digest or tag that you want to delete.","metadata":{}},{"cell_type":"code","source":"aws ecr describe-images --repository-name <repository-name>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace <repository-name> with the name of your ECR repository.\n\n**Step 2: Delete the Image**\n\nOnce you have identified the image tag or digest you want to delete, you can use the AWS CLI to delete it:","metadata":{}},{"cell_type":"code","source":"aws ecr batch-check-layer-availability --region <region> --repository-name <repository-name> --image-ids imageTag=<tag>\naws ecr batch-delete-image --region <region> --repository-name <repository-name> --image-ids imageTag=<tag>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace <region> with your AWS region and <repository-name> and <tag> with the name of the ECR repository and the image tag or digest you want to delete.\n\nPlease note that batch-delete-image is a destructive operation, and it permanently deletes the specified images. Be cautious when using it.","metadata":{}},{"cell_type":"markdown","source":"### 2. Python scipt that automates the process\n\nIf you want to perform image deletion programmatically using Python, you can create a Python script that executes these AWS CLI commands using the subprocess module:","metadata":{}},{"cell_type":"code","source":"import subprocess\n\n# Define the ECR repository name and image tag to delete\nrepository_name = 'your-repo-name'\nimage_tag = 'your-image-tag'\n\n# Step 1: Batch check layer availability\ncheck_layer_command = f'aws ecr batch-check-layer-availability --region your-region --repository-name {repository_name} --image-ids imageTag={image_tag}'\nsubprocess.run(check_layer_command, shell=True, check=True)\n\n# Step 2: Batch delete image\ndelete_image_command = f'aws ecr batch-delete-image --region your-region --repository-name {repository_name} --image-ids imageTag={image_tag}'\nsubprocess.run(delete_image_command, shell=True, check=True)\n\nprint(f\"Deleted image {repository_name}:{image_tag}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace 'your-region', 'your-repo-name', and 'your-image-tag' with your AWS region, ECR repository name, and the image tag you want to delete.\n\nRemember to use this script with caution, as it permanently removes images from your ECR repository. Make sure you have the necessary AWS IAM permissions to perform this action.","metadata":{}},{"cell_type":"markdown","source":"## 6. Managing Lifecycle Policies","metadata":{}},{"cell_type":"markdown","source":"Managing lifecycle policies in Amazon Elastic Container Registry (ECR) allows you to automatically clean up old images based on certain rules or policies. Below are the steps and code for managing lifecycle policies in ECR:\n\n**Step 1: Authenticate with AWS**\n\nEnsure that you are authenticated with AWS using the AWS CLI. You should have the necessary permissions to manage repositories and policies in ECR.\n\n**Step 2: Create a JSON Policy File**\n\nYou need to create a JSON file that defines your ECR lifecycle policy. The policy specifies the rules for image retention and cleanup. Here's an example JSON policy:","metadata":{}},{"cell_type":"code","source":"{\n  \"rules\": [\n    {\n      \"rulePriority\": 1,\n      \"description\": \"Keep 30 most recent images\",\n      \"selection\": {\n        \"tagStatus\": \"untagged\",\n        \"countType\": \"imageCountMoreThan\",\n        \"countNumber\": 30\n      },\n      \"action\": {\n        \"type\": \"expire\"\n      }\n    },\n    {\n      \"rulePriority\": 2,\n      \"description\": \"Keep images tagged with 'latest' for 7 days\",\n      \"selection\": {\n        \"tagStatus\": \"tagged\",\n        \"tagPrefixList\": [\"latest\"],\n        \"countType\": \"sinceImagePushed\",\n        \"countNumber\": 7\n      },\n      \"action\": {\n        \"type\": \"expire\"\n      }\n    }\n  ]\n}\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This JSON file defines two rules: one to keep the 30 most recent untagged images and another to keep images tagged with 'latest' for 7 days before expiring them.\n\n**Step 3: Create or Update the Lifecycle Policy**\n\nTo create or update a lifecycle policy, you can use the put-lifecycle-policy AWS CLI command:","metadata":{}},{"cell_type":"code","source":"aws ecr put-lifecycle-policy --repository-name <repository-name> --lifecycle-policy-text file://<path-to-policy-file>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace <repository-name> with the name of your ECR repository and <path-to-policy-file> with the path to the JSON policy file you created in Step 2.\n\n**Step 4: Describe the Lifecycle Policy (Optional)**\n\nYou can use the describe-lifecycle-policy AWS CLI command to view the details of the lifecycle policy:","metadata":{}},{"cell_type":"code","source":"aws ecr describe-lifecycle-policy --repository-name <repository-name>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This step is optional but can be useful for verifying the policy settings.\n\n**Step 5: Apply the Policy to the Repository (Optional)**\n\nBy default, when you create or update a lifecycle policy, it does not automatically apply to existing images in the repository. To apply the policy to existing images, you can use the start-lifecycle-policy-preview AWS CLI command:","metadata":{}},{"cell_type":"code","source":"aws ecr start-lifecycle-policy-preview --repository-name <repository-name>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This step is also optional, and you may choose to wait for new images to be subject to the policy.\n\nThe policy will automatically manage image retention and cleanup based on the rules defined in the JSON policy file.","metadata":{}},{"cell_type":"markdown","source":"## 7. Copying Images:  \n\nCopying Docker images from one Elastic Container Registry (ECR) repository to another can be accomplished using the AWS Command Line Interface (CLI). Below are the steps and code to copy Docker images between ECR repositories:\n\n**Step 1: Authenticate with AWS**\n\nEnsure that you are authenticated with AWS using the AWS CLI. You should have the necessary permissions to access both the source and destination ECR repositories.\n\n**Step 2: Check Layer Availability (Optional)**\n\nBefore copying an image, it's a good practice to check the layer availability in the destination repository. This step is optional but can be used to ensure that the necessary image layers are available in the destination repository.","metadata":{}},{"cell_type":"code","source":"aws ecr batch-check-layer-availability --region <destination-region> --repository-name <destination-repo-name> --image-ids imageTag=<tag>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace <destination-region> with the AWS region of the destination repository, <destination-repo-name> with the name of the destination repository, and <tag> with the image tag you want to copy.\n\n**Step 3: Authenticate with the Destination Repository**\n\nTo push the image to the destination repository, you need to authenticate with it.","metadata":{}},{"cell_type":"code","source":"aws ecr get-login-password --region <destination-region> | docker login --username AWS --password-stdin <destination-account-id>.dkr.ecr.<destination-region>.amazonaws.com\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace <destination-region> with the AWS region of the destination repository, <destination-account-id> with the AWS account ID of the destination repository.\n\n**Step 4: Tag the Image**\n\nTag the Docker image from the source repository with the destination repository URI.","metadata":{}},{"cell_type":"code","source":"docker tag <source-repo-uri>:<tag> <destination-repo-uri>:<tag>\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace <source-repo-uri> with the URI of the source repository, <tag> with the image tag, and <destination-repo-uri> with the URI of the destination repository.\n\n**Step 5: Push the Image to the Destination Repository**\n\nPush the Docker image to the destination ECR repository.","metadata":{}},{"cell_type":"code","source":"docker push <destination-repo-uri>:<tag>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace <destination-repo-uri> with the URI of the destination repository and <tag> with the image tag.\n\n**Step 6: Verify the Image in the Destination Repository**\n\nYou can now verify that the Docker image has been copied to the destination repository by listing the images in the destination repository:","metadata":{}},{"cell_type":"code","source":"aws ecr list-images --repository-name <destination-repo-name> --region <destination-region>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace <destination-repo-name> with the name of the destination repository and <destination-region> with the AWS region of the destination repository.\n\nBy following these steps and using the AWS CLI and Docker commands, you can copy Docker images from one ECR repository to another.","metadata":{}},{"cell_type":"markdown","source":"## 8. Integrating with CI/CD using GitLab CI/CD","metadata":{}},{"cell_type":"markdown","source":"Integrating Helm with your CI/CD pipeline for managing Docker-based applications in Kubernetes involves several steps. Helm is a package manager for Kubernetes that simplifies the deployment and management of applications. Below are the steps to integrate Helm with Docker in a CI/CD pipeline:\n\n**Step 1: Prepare Your Helm Charts**\n\nMake sure you have Helm charts for your applications ready in your project repository. Helm charts define how your application should be deployed in Kubernetes, including Docker image references, configuration values, and dependencies.\n\n**Step 2: Create or Edit .gitlab-ci.yml**\n\nEdit your project's .gitlab-ci.yml file to define the CI/CD pipeline stages for building and deploying Docker images and managing Helm charts. Here's a sample .gitlab-ci.yml file:","metadata":{}},{"cell_type":"code","source":"stages:\n  - build\n  - deploy\n\nvariables:\n  DOCKER_IMAGE_NAME: your-docker-image-name\n  DOCKER_IMAGE_TAG: $CI_COMMIT_SHORT_SHA\n  HELM_CHART_NAME: your-helm-chart-name\n\nbefore_script:\n  - # Authenticate with your container registry (e.g., Docker Hub)\n    - echo \"$DOCKER_PASSWORD\" | docker login -u \"$DOCKER_USERNAME\" --password-stdin\n\nbuild:\n  stage: build\n  script:\n    - # Build your Docker image\n      - docker build -t $DOCKER_IMAGE_NAME:$DOCKER_IMAGE_TAG .\n    - # Push the Docker image to your container registry\n      - docker push $DOCKER_IMAGE_NAME:$DOCKER_IMAGE_TAG\n  only:\n    - branches\n  except:\n    - tags\n\ndeploy:\n  stage: deploy\n  script:\n    - # Deploy Helm chart to your Kubernetes cluster\n      - helm upgrade --install $HELM_CHART_NAME ./path/to/helm/chart --set image.tag=$DOCKER_IMAGE_TAG\n  only:\n    - branches\n  except:\n    - tags\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this example:\n\nReplace your-docker-image-name with the name of your Docker image.\nReplace your-helm-chart-name with the name of your Helm chart.\nThe Docker image is built and pushed to your container registry (e.g., Docker Hub).\nThe Helm chart is deployed to your Kubernetes cluster using the Docker image tag as a variable.\n\n**Step 3: Commit and Push .gitlab-ci.yml**\n\nCommit the .gitlab-ci.yml file to your GitLab repository and push it to trigger the CI/CD pipeline.\n\n**Step 4: CI/CD Pipeline Execution**\n\nGitLab CI/CD will automatically build your Docker image and push it to your container registry when changes are pushed to the repository. After a successful build, the Helm chart is deployed to your Kubernetes cluster with the updated Docker image tag.\n\nEnsure that you have Docker, Helm, and kubectl installed in your CI/CD runner environment. Additionally, configure environment variables for your container registry credentials (e.g., DOCKER_USERNAME and DOCKER_PASSWORD) securely in your GitLab CI/CD settings.\n\nThis configuration allows you to automate the deployment of your Docker-based applications in Kubernetes using Helm as part of your CI/CD pipeline. Make any necessary adjustments based on your specific project requirements and container registry configuration.","metadata":{}}]}